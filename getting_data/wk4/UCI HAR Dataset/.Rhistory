cashSolve(m1)
rm(list=ls())
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
makeCacheMatrix <- function(x = matrix()) {
invrs <- NULL
set <- function(y) {
x <<- y
invrs  <<- NULL
}
get <- function() x
setInverse <- function(inverse) invrs <<- inverse
getInverse <- function() invrs
list(set = set, get = get,
setInverse = setInverse,
getInverse = getInverse)
}
cacheSolve <- function(x, ...) {
invrs <- x$getInverse()
if(!is.null(invrs)) {
message("getting cached data")
return(invrs)
}
mtx <- x$get()
invrs <- solve(mtx, ...)
x$setInverse(invrs)
invrs
}
m1 <- makeCacheMatrix(2)
cacheSolve(m1)
makeCacheMatrix <- function(x = matrix()) {
invs <- NULL
set <- function(y) {
x <<- y
invs  <<- NULL
}
get <- function() x
setInverse <- function(inverse) invs <<- inverse
getInverse <- function() invs
list(set = set, get = get,
setInverse = setInverse,
getInverse = getInverse)
}
cacheSolve <- function(x, ...) {
invs <- x$getInverse()
if(!is.null(invrs)) {
message("getting cached data")
return(invrs)
}
mtx <- x$get()
invs <- solve(mtx, ...)
x$setInverse(invs)
invs
}
m2 <- makeCacheMatrix(matrix(1:20,4,5))
m2$get()
cacheSolve(m2)
cacheSolve <- function(x, ...) {
invs <- x$getInverse()
if(!is.null(invrs)) {
message("getting cached data")
return(invs)
}
mtx <- x$get()
invs <- solve(mtx, ...)
x$setInverse(invs)
invs
}
cacheSolve(m2)
cacheSolve <- function(x, ...) {
invs <- x$getInverse()
if(!is.null(invs)) {
message("getting cached data")
return(invs)
}
mtx <- x$get()
invs <- solve(mtx, ...)
x$setInverse(invs)
invs
}
cacheSolve(m2)
m3 <- makeCacheMatrix(matrix(1:16,4,4))
cacheSolve(m3)
m4 <- makeCacheMatrix(matrix(1:4, 2, 2))
cacheSolve(m4)
m3
m4$get()
m4$getInverse()
?solve
makeCashMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
t setinverse <- function(inverse) i <<- inverse
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y = matrix()) {
x <<- y
m <<- NULL
}
get <- function() x
setinv <- function(inv) m <<- inv
getinv <- function() m
clearinv <- function() m <<- NULL
list(set = set, get = get,
setinv = setinv,
getinv = getinv,
clearinv = clearinv)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinv()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data, ...)
x$setinv(m)
m
}
m1 <- makeCacheMatrix(matrix(1:4,2,2))
cacheSolve(m1)
m1
m1$get()
swirl()
library(swirl)
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6,4,replace = TRUE)
sample(1:6,4,replace = TRUE)
sample(1:10,4)
sample(1:20,10)
LETTERS
sample(LETTERS)
flips <- sample(c(0,1),100,replace = TRUE,prob = c(0.3, 0.7))
flips
sum(flips[1])
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(100,size size = 1, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean = 100,sd=25)
rpois(5,mean = 10)
?rpois
rpois,5,10
rpois(5,10)
replicate(100,rpois(5,10))
mymy_pois <- replicate(100, rpois(5, 10))
my_pois <- replicate(100, rpois(5, 10))
my_pois
colMeans(my_pois)
cm <- colMeans(my_pois)
hist(cm)
swirl()
data("cars")
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(cars$speed,cars$dist)
plot(cars$dist,cars$speed)
?plot
plot(cars$speed,cars$dist,xlab = "Speed")
plot(cars$speed,cars$dist,xlab = "Speed",ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(cars$speed,cars$dist,xlab = "Speed",ylab = "Stopping Distance")
plot(cars,main="My Plot")
plot(cars,sub="My Plot Subtitle")
plot(cars,col=2)
plot(cars,xlim=c(10,15))
plot(cars,pch=2)
data("mtcars")
data(mtcars)
?boxplot
boxplot(formula = mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
exit
str(lm)
str(ncol)
str(nrow)
str(ls)
library(datasets)
data(mtcars)
str(mtcars)
x <- rnorm(100,2,4)
str(x)
g <- gl(40,5)
str(g)
str(airquality)
m <- matrix(rnorm(100),5,20)
str(m)
m[,6]
m,2,7
m[2,7]
dnorm(x,mean=0,sd=1,log=false)
dnorm(x,mean=0,sd=1,log=FALSE)
str(rnorm)
str(set.seed)
?set.seed
rpois(10,1)
rpois(2,3)
ppois(2,2)
str(ppois)
set.seed(20)
x <- rnorm(100)
e <- rnorm(100,0,2)
y <- 0.5 + 2 * x + e
plot(x,y)
hist(x)
hist(y)
set.seed(10)
x1 <- rbinom
e1 <- rnorm(100,0,2)
x1 <- rbinom(100,1,0.5)
y1 <- 0.5 + 2 * x1 + e1
plot(x1,y1)
summary(y1)
set.seed(1)
x2 <- rnorm(100)
log.mu <- 0.5 + 0.3 * x2
y2 <- rpois(100,exp(log.mu))
plot(x2,y2)
sample(1:10,4)
sample(1:10
)
sample(letters,4)
con = url("https://www.reddit.com/r/ukpolitics/comments/4q972b/somebody_needs_to_come_out_and_say_that/")
rUKpol = readLines(con)
con = url("http://www.reddit.com/r/ukpolitics/comments/4q972b/somebody_needs_to_come_out_and_say_that/")
rUKpol = readLines(con)
library(XML)
close(con)
url <- "https://www.reddit.com/r/ukpolitics/comments/4q972b/somebody_needs_to_come_out_and_say_that/"
html <- htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html, "//title",xmlValue)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html, "//title",xmlValue)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html, "//title",xmlValue)
url2 <- "http://www.reddit.com/r/ukpolitics/comments/4q972b/somebody_needs_to_come_out_and_say_that/"
html2 <- htmlTreeParse(url2,useInternalNodes = T)
html
html2
html2 <- htmlTreeParse(url2,useInternalNodes = T)
library(RCurl)
rUK <- getURL(url2)
rUK <- readHTMLTable(rUK,stringsAsFactors = F)
url2
head(rUKpol)
url2
library(httr); html2 = GET(url2)
library(httr); html = GET(url2)
library(httr)
html1 = GET(url2)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html, "//title",xmlValue)
library(httr); html = GET(url)
library(httr); html2 = GET(url)
content2 = content(html2,as ="text" )
parsedHtml = htmlParse(content2,asText = TRUE)
xpathSApply(parsedHtml,"//title",xmlValue)
myapp = oauth_app("twitter"
key="sJYNNXZfGbqBbbaFGOUyg",secret="N2H30wZRIPopehgIU2Go6HzIbgGvcWQ2V5zN5a7WH0")
myapp = oauth_app("twitter",
key="sJYNNXZfGbqBbbaFGOUyg",secret="N2H30wZRIPopehgIU2Go6HzIbgGvcWQ2V5zN5a7WH0")
sig = sign_oauth1.0(myapp,
token = "119105679-Pl04vtcXSnEdVGOirIVAkquhSXZB4QsNfh2Gd55Z",
token_secret = "U9WVhTJ4VVUsbI3U2WorVqHnkeLDc19t4aVwfNSQ")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
install.packages("openssl")
library(openssl)
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
homeTL
head(homeTL)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json2[5,1:4]
names(json2)
?zip.unpack
library(foreign)
install.packages("RPostresSQL")
install.packages("RPostgreSQL")
install.packages("RODBC")
install.packages("RMongo")
install.packages(c("jpeg", "readbitmap", "png"))
install.packages("caTools")
install.packages("tuneR")
install.packages("seewave")
install.packages("sqldf")
git_id = "0f0a2fd5902ce287334a"
git_secret = "e2e13b19c6faaec7ed7eb1819311088f2c78fdc2"
gitAPI <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitAPI)
install.packages("Rcpp")
library(Rcpp)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitAPI)
?oauth_endpoints
install.packages("httr")
install.packages("httr")
gitApp <- oauth_app("github", git_id, git_secret)
oauth_endpoints("github")
oaut
oauth_endpoints(gitApp)
?oauth_app
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
install.packages("httpuv")
install.packages("httpuv")
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
library(jsonlite)
library(httr)
library(httpuv)
install.packages(httpuv)
install.packages("httpuv")
git_id = "0f0a2fd5902ce287334a"
git_secret = "e2e13b19c6faaec7ed7eb1819311088f2c78fdc2"
gitApp <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
library(jsonlite)
library(httr)
library(httpuv)
install.packages(c("bigrquery", "checkmate", "crayon", "DBI", "devtools", "httr", "jsonlite", "plyr", "RMySQL"))
install.packages(c("bigrquery", "checkmate", "crayon", "DBI",
)
install.packages(c("bigrquery", "checkmate", "crayon", "DBI", "devtools", "httr", "jsonlite", "plyr", "RMySQL"))
install.packages(c("bigrquery", "checkmate", "crayon", "DBI",
git_id = "8188eaaa449ff7cbe169"
git_secret = "c03528f11f49e3d46dd81edfd28224b41b049b49"
library(jsonlite)
library(httr)
library(httpuv)
gitApp <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
library(jsonlite)
library(httr)
library(httpuv)
git_id = "0f0a2fd5902ce287334a"
git_secret = "e2e13b19c6faaec7ed7eb1819311088f2c78fdc2"
gitApp <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
install.packages(c("httr", "jsonlite"))
install.packages(c("httr", "jsonlite"))
install.packages(c("httr", "jsonlite"))
install.packages(c("plyr", "RMySQL"))
install.packages(c("bigrquery", "checkmate", "crayon", "DBI"))
library(jsonlite)
library(httr)
library(Rcpp)
library(httpuv)
git_id = "0f0a2fd5902ce287334a"
git_secret = "e2e13b19c6faaec7ed7eb1819311088f2c78fdc2"
gitApp <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
git_id = "0f0a2fd5902ce287334a"
git_secret = "e2e13b19c6faaec7ed7eb1819311088f2c78fdc2"
gitApp <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
library(jsonlite)
library(httr)
library(Rcpp)
library(httpuv)
git_id = "0f0a2fd5902ce287334a"
git_secret = "e2e13b19c6faaec7ed7eb1819311088f2c78fdc2"
gitApp <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
?httpuv
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
library(jsonlite)
library(httr)
library(httpuv)
gitApp
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
?readRDS
library(sqdlf)
library(sqldf)
acsURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
doc <- file.path(getwd(),"acsdata.csv")
download.file(acsURL,doc)
acs <- data.table(read.csv(doc))
library(data.table)
acs <- data.table(read.csv(doc))
sqldf("select * from acs")
q2 <- sqldf("select * from acs where AGEP < 50")
q2
q3 <- sqldf("select pwgtp1 from acs where AGEP < 50")
q3
q4 <- qldf("select pwgtp1 from acs")
q4 <- sqldf("select pwgtp1 from acs")
q4
q3
unique(acs$AGEP)
unique(acs$AGEP) = sqldf("select distinct pwgtp1 from acs")
q3 <- unique(acs$AGEP)
q3a1 <- sqldf("select distinct pwgtp1 from acs")
q3 = q3a1
q3 <- unique(acs$AGEP)
q3 == q3a1
q3a2 <- sqldf("select distinct AGEP from acs")
q3a3 <- sqldf("select AGEP where unique from acs")
q3a4 <- sqldf("select unique AGEP from acs")
q3 == q3a2
library(nch)
connection <- url("http://biostat.jhsph.edu/~jleek/contact.html")
q4 <- readLines(connection)
close(connection)
c(nchar(q4[10]), nchar(q4[20]), nchar(q4[30]), nchar(q4[100]))
q5URL = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
q5 <- readLines(q5URL, n=9)
q5
sum(q5[,4])
head(q5)
q5[,5]
q5[5,]
str(q5)
class(q5)
q5[4,]
library(fwf)
install.packages(fwf)
install.packages("read.fwf")
install.packages("readr")
library(readr)
x <- read_fwf(q5URL,skip = 4,fwf_widths(c(12,7,4,9,4,9,4,9,4)))
sum(x[,4])
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
library(httr)
library(httpuv)
require(httpuv)
require(jsonlite)
gitApp <- oauth_app("github", git_id, git_secret)
git_token <- oauth2.0_token(oauth_endpoints("github"),gitApp)
?readRDS
library(data.table)
library(dplyr)
getwd()
setwd("C:/Users/Randall/rhelms_data/ExData_Plotting1")
if(!file.exists("./data")){dir.create("./data")}
fileURL <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
download.file(fileURL,destfile = "./data/power.zip",method = "curl")
unzip("./data/power.zip")
list.files()
file = "household_power_consumption.txt"
power <- fread(file, na.strings = "?",sep = ";")
power2 <- filter(power, power$Date=="1/2/2007" | power$Date == "2/2/2007")
rm(power)
power2$dateTime <- strptime(paste(power2$Date,power2$Time, sep = " "), format="%d/%m/%Y %H:%M:%S")
setwd("C:/Users/Randall/rhelms_data/")
list.dirs()
setwd("C:/Users/Randall/rhelms_data/datasciencecoursera/getting_data/wk4")
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL,destfile = "./data/wearables.zip",method = "curl")
list.files() #find file names
unzip("./data/wearables.zip")
list.files()
getwd()
setwd("C:/Users/Randall/rhelms_data/datasciencecoursera/getting_data/wk4/UCI HAR Dataset")
list.files()
